# LAB02 - Citation Matching & Entity Resolution

![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)
![scikit-learn](https://img.shields.io/badge/scikit--learn-1.0+-orange.svg)
![Jupyter](https://img.shields.io/badge/Jupyter-Notebook-orange.svg)
![License](https://img.shields.io/badge/License-MIT-green.svg)
![Status](https://img.shields.io/badge/Status-Active-success.svg)

> Há»‡ thá»‘ng tá»± Ä‘á»™ng khá»›p citation trong tÃ i liá»‡u khoa há»c sá»­ dá»¥ng Machine Learning Ä‘á»ƒ giáº£i quyáº¿t bÃ i toÃ¡n Entity Resolution trong scientific papers.

---

## Má»¥c lá»¥c

- [Giá»›i thiá»‡u](#giá»›i-thiá»‡u)
- [ThÃ´ng tin sinh viÃªn](#thÃ´ng-tin-sinh-viÃªn)
- [Kiáº¿n trÃºc há»‡ thá»‘ng](#kiáº¿n-trÃºc-há»‡-thá»‘ng)
- [CÃ i Ä‘áº·t](#cÃ i-Ä‘áº·t)
- [HÆ°á»›ng dáº«n sá»­ dá»¥ng](#hÆ°á»›ng-dáº«n-sá»­-dá»¥ng)
  - [BÆ°á»›c 1: Parse LaTeX Files](#bÆ°á»›c-1-parse-latex-files)
  - [BÆ°á»›c 2: Matching & Feature Extraction](#bÆ°á»›c-2-matching--feature-extraction)
  - [BÆ°á»›c 3: Training & Evaluation](#bÆ°á»›c-3-training--evaluation)
- [Cáº¥u trÃºc dá»¯ liá»‡u](#cáº¥u-trÃºc-dá»¯-liá»‡u)
- [Káº¿t quáº£](#káº¿t-quáº£)
- [Cáº¥u trÃºc thÆ° má»¥c](#cáº¥u-trÃºc-thÆ°-má»¥c)

---

## Giá»›i thiá»‡u

Dá»± Ã¡n nÃ y giáº£i quyáº¿t bÃ i toÃ¡n **Citation Matching** - má»™t dáº¡ng cá»§a **Entity Resolution** trong lÄ©nh vá»±c xá»­ lÃ½ tÃ i liá»‡u khoa há»c. Há»‡ thá»‘ng tá»± Ä‘á»™ng:

- **TrÃ­ch xuáº¥t** citation references tá»« LaTeX source code
- **Khá»›p** cÃ¡c citation keys vá»›i cÃ¡c papers trong database
- **Huáº¥n luyá»‡n** mÃ´ hÃ¬nh Machine Learning (Random Forest) Ä‘á»ƒ dá»± Ä‘oÃ¡n matching
- **ÄÃ¡nh giÃ¡** báº±ng chá»‰ sá»‘ MRR@5 (Mean Reciprocal Rank)

### TÃ­nh nÄƒng chÃ­nh

- Parse LaTeX files vÃ  trÃ­ch xuáº¥t bibliography items
- Matching thÃ´ng minh giá»¯a citation keys vÃ  reference papers
- Feature engineering vá»›i 11 features dÃ¹ng cho huáº¥n luyá»‡n
- Train/test split theo publication-level
- Hyperparameter tuning vá»›i GridSearchCV
- Evaluation vá»›i MRR@5 metric

### CÃ´ng nghá»‡ sá»­ dá»¥ng

- **Python 3.10+** - NgÃ´n ngá»¯ láº­p trÃ¬nh chÃ­nh
- **Jupyter Notebook** - MÃ´i trÆ°á»ng phÃ¡t triá»ƒn
- **scikit-learn** - Machine Learning framework
- **pandas** - Xá»­ lÃ½ dá»¯ liá»‡u
- **numpy** - TÃ­nh toÃ¡n sá»‘ há»c
- **matplotlib, seaborn** - Visualization
- **joblib** - Model serialization
- **tqdm** - Progress bars

---

## ThÃ´ng tin sinh viÃªn

| ThÃ´ng tin | GiÃ¡ trá»‹ |
|-----------|---------|
| **MSSV** | 23120334 |
| **Há» vÃ  tÃªn** | Huá»³nh Táº¥n PhÆ°á»›c |
| **Email** | 23120334@student.hcmus.edu.vn |
| **MÃ´n há»c** | Nháº­p mÃ´n Khoa há»c dá»¯ liá»‡u |
| **Lá»›p** | CQ2023/21 |

---

## Kiáº¿n trÃºc há»‡ thá»‘ng

Há»‡ thá»‘ng Ä‘Æ°á»£c chia thÃ nh 3 giai Ä‘oáº¡n chÃ­nh:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    WORKFLOW PIPELINE                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. PARSE STAGE
   â””â”€> LaTeX files â†’ bibitems.jsonl + references.jsonl

2. MATCH & FE STAGE  
   â””â”€> bibitems + references â†’ matches_fe.jsonl
   â””â”€> Split train/val/test
   â””â”€> Generate pred.json

3. MODELING STAGE
   â””â”€> Train Random Forest
   â””â”€> Hyperparameter Tuning
   â””â”€> Evaluate MRR@5
```

### Pipeline chi tiáº¿t

1. **Parse LaTeX Files** (`parse_runner.ipynb`)
   - Äá»c LaTeX source tá»« thÆ° má»¥c `23120334/{paper_id}/tex/`
   - TrÃ­ch xuáº¥t bibliography items tá»« `.bib` files
   - TrÃ­ch xuáº¥t references tá»« `.tex` files
   - Táº¡o `aggregated/bibitems.jsonl` vÃ  `aggregated/references.jsonl`

2. **Matching & Feature Extraction** (`match_and_fe.ipynb`)
   - Khá»›p citation keys vá»›i reference papers
   - TÃ­nh toÃ¡n features dÃ¹ng cho mÃ´ hÃ¬nh

#### Model Features

| Feature | CÃ´ng thá»©c/TÃ­nh toÃ¡n | Sá»­ dá»¥ng | LÃ½ do |
|---------|-------------------|---------|-------|
| **levenshtein** | `1 - (edit_distance / max(len(a), len(b)))` | CÃ³ | Äo Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng chuá»—i, quan trá»ng cho text matching |
| **year_match** | `1` náº¿u `source_year == cand_year`, `0` náº¿u khÃ´ng | CÃ³ | Feature quan trá»ng (importance ~0.049) |
| **year_diff** | `\|source_year - cand_year\|` hoáº·c `100` náº¿u thiáº¿u | CÃ³ | Feature quan trá»ng thá»© 2 (importance ~0.213) |
| **source_year** | NÄƒm xuáº¥t báº£n tá»« bibitem | CÃ³ | Context feature cho model |
| **cand_year** | NÄƒm xuáº¥t báº£n tá»« reference | CÃ³ | Context feature cho model |
| **author_overlap** | Jaccard overlap tÃªn Ä‘áº§y Ä‘á»§: `\|set(authors_a) & set(authors_b)\| / \|set(authors_a) \| set(authors_b)\|` | CÃ³ | Feature quan trá»ng (importance ~0.039) |
| **author_lastname_match** | `1` náº¿u cÃ³ báº¥t ká»³ tÃªn há» trÃ¹ng, `0` náº¿u khÃ´ng | CÃ³ | Feature quan trá»ng nháº¥t (importance ~0.587) |
| **author_firstname_match** | `1` náº¿u cÃ³ báº¥t ká»³ tÃªn Ä‘áº§u trÃ¹ng, `0` náº¿u khÃ´ng | KhÃ´ng | Bá»‹ loáº¡i bá» - khÃ´ng Ä‘Æ°á»£c tÃ­nh trong compute_features |
| **token_overlap** | `\|set(tokens_a) & set(tokens_b)\|` | KhÃ´ng | Bá»‹ loáº¡i bá» - trÃ¹ng vá»›i author_overlap, char n-grams |
| **token_overlap_ratio** | `\|set(tokens_a) & set(tokens_b)\| / max(len(tokens_a), len(tokens_b))` | KhÃ´ng | Bá»‹ loáº¡i bá» - trÃ¹ng vá»›i token_overlap |
| **char_ngram_3** | Jaccard overlap 3-gram kÃ½ tá»± | KhÃ´ng | Bá»‹ loáº¡i bá» - redundant vá»›i levenshtein |
| **char_ngram_4** | Jaccard overlap 4-gram kÃ½ tá»± | KhÃ´ng | Bá»‹ loáº¡i bá» - redundant vá»›i levenshtein |
| **char_ngram_5** | Jaccard overlap 5-gram kÃ½ tá»± | KhÃ´ng | Bá»‹ loáº¡i bá» - redundant vá»›i levenshtein |

   - Negative sampling (5000 negatives per positive)
   - Táº¡o train/val/test split (publication-level)
   - Sinh `pred.json` cho má»—i paper

3. **Modeling & Evaluation** (`modeling.ipynb`)
   - Load dá»¯ liá»‡u tá»« `split/` directory
   - Hyperparameter tuning vá»›i GridSearchCV
   - Train Random Forest Classifier
   - ÄÃ¡nh giÃ¡ báº±ng MRR@5 metric
   - Táº¡o predictions vÃ  cáº­p nháº­t `pred.json`

---

## CÃ i Ä‘áº·t

### YÃªu cáº§u há»‡ thá»‘ng

- Python 3.10 trá»Ÿ lÃªn
- pip package manager
- ~10GB dung lÆ°á»£ng á»• cá»©ng (cho dataset vÃ  models)

### Thiáº¿t láº­p mÃ´i trÆ°á»ng

#### Windows

```bash
# Táº¡o mÃ´i trÆ°á»ng áº£o
python -m venv .venv

# KÃ­ch hoáº¡t mÃ´i trÆ°á»ng
.venv\Scripts\activate

# NÃ¢ng cáº¥p pip
pip install --upgrade pip

# CÃ i Ä‘áº·t dependencies
pip install -r requirements.txt
```

#### Linux/macOS

```bash
# Táº¡o mÃ´i trÆ°á»ng áº£o
python3 -m venv .venv

# KÃ­ch hoáº¡t mÃ´i trÆ°á»ng
source .venv/bin/activate

# NÃ¢ng cáº¥p pip
pip install --upgrade pip

# CÃ i Ä‘áº·t dependencies
pip install -r src/requirements.txt
```

#### Google Colab (Khuyáº¿n nghá»‹)

**ğŸ“ Dá»¯ liá»‡u dá»± Ã¡n**: [Google Drive](https://drive.google.com/drive/folders/1RJC81xq4osFdIOGtwy_pKQoxlwGW3FZC?usp=sharing)

**Cáº¥u trÃºc thÆ° má»¥c trong Drive**:
```
23120334/
â”œâ”€â”€ aggregated/      # Dá»¯ liá»‡u Ä‘Ã£ aggregate
â”œâ”€â”€ notebooks/       # Jupyter notebooks
â”œâ”€â”€ src/            # Source code
â””â”€â”€ 23120334/       # Papers data
```

**Thiáº¿t láº­p trÃªn Colab**:

```python
# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Chuyá»ƒn Ä‘áº¿n thÆ° má»¥c dá»± Ã¡n
%cd "/content/drive/MyDrive/23120334"

# CÃ i Ä‘áº·t dependencies
!pip install -r requirements.txt
```

**LÆ°u Ã½**: Dá»± Ã¡n Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ cháº¡y trÃªn Google Colab. Vui lÃ²ng táº£i toÃ n bá»™ thÆ° má»¥c tá»« Google Drive vÃ  mount vÃ o Colab theo cáº¥u trÃºc trÃªn.

### Dependencies chÃ­nh

- `pandas` - Xá»­ lÃ½ dá»¯ liá»‡u
- `scikit-learn` - Machine Learning
- `numpy` - TÃ­nh toÃ¡n sá»‘ há»c
- `matplotlib`, `seaborn` - Visualization
- `tqdm` - Progress bars
- `joblib` - Model serialization

---

## HÆ°á»›ng dáº«n sá»­ dá»¥ng

> **âš ï¸ LÆ°u Ã½**: Dá»± Ã¡n Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ cháº¡y trÃªn **Google Colab**. Vui lÃ²ng táº£i dá»¯ liá»‡u tá»« [Google Drive](https://drive.google.com/drive/folders/1RJC81xq4osFdIOGtwy_pKQoxlwGW3FZC?usp=sharing) vÃ  mount vÃ o Colab theo cáº¥u trÃºc thÆ° má»¥c Ä‘Ã£ cung cáº¥p.

### BÆ°á»›c 1: Parse LaTeX Files

Notebook: `notebooks/parse_runner.ipynb`

**Má»¥c Ä‘Ã­ch**: TrÃ­ch xuáº¥t bibliography items vÃ  references tá»« LaTeX source code.

**Cáº¥u hÃ¬nh**:

```python
RUN_ALL = True           # True: xá»­ lÃ½ nhiá»u paper; False: chá»‰ 1 paper
PAPER_ID = "2408-02468"  # DÃ¹ng khi RUN_ALL=False
START = "2408-02468"     # DÃ¹ng khi RUN_ALL=True
NUM = 5000               # Giá»›i háº¡n sá»‘ paper
```

**Cháº¡y (theo thá»© tá»± cell)**:

1. Cell cáº¥u hÃ¬nh + import (Ä‘áº·t `RUN_ALL`, `PAPER_ID`, `START`, `NUM`)
2. Cell "Run Parser"
3. Cell "Statistics"
4. Cell "Visualization" (tÃ¹y chá»n)
5. Cell "Quick Check"

**Káº¿t quáº£**:
   - `aggregated/bibitems.jsonl`
   - `aggregated/references.jsonl`

**Output máº«u** (`bibitems.jsonl`):

```json
{
  "paper_id": "2408-02468",
  "key": "zhang2021counterfactual",
  "title": "Counterfactual Learning...",
  "authors": ["Zhang", "Li"],
  "year": 2021,
  "arxiv": "2112.12938"
}
```

---

### BÆ°á»›c 2: Matching & Feature Extraction

Notebook: `notebooks/match_and_fe.ipynb`

**Má»¥c Ä‘Ã­ch**: 
- Khá»›p citation keys vá»›i reference papers
- TÃ­nh toÃ¡n features
- Táº¡o train/val/test split
- Sinh file `pred.json` cho má»—i paper

**Cáº¥u hÃ¬nh**:

```python
NEG_PER_POS = 5000       # Sá»‘ negative samples per positive
RANDOM_SEED = 23120334   # Random seed Ä‘á»ƒ reproducibility
START = "2408-02468"     # Lá»c paper tá»« ID nÃ y
NUM = 600                # Sá»‘ paper tá»‘i Ä‘a
MAX_REFS = None          # Giá»›i háº¡n references (None = khÃ´ng giá»›i háº¡n)
MAX_BIBS = None          # Giá»›i háº¡n bibitems (None = khÃ´ng giá»›i háº¡n)
```

**Cháº¡y (theo thá»© tá»± cell)**:

1. Cell cáº¥u hÃ¬nh + import (Ä‘áº·t `NEG_PER_POS`, `START`, `NUM`, `MAX_REFS`, `MAX_BIBS`)
2. Cell "Load Manual Candidates" (náº¿u cÃ³)
3. Cell "Run Matching and Feature Extraction"
4. Cell "Statistics"
5. Cell "Visualization" (tÃ¹y chá»n)
6. Cell "Data Splitting" Ä‘á»ƒ táº¡o `split/` vÃ  `pred.json`

**Output**:

- `aggregated/matches_fe.jsonl`: Táº¥t cáº£ cáº·p (bib_key, candidate) vá»›i features
- `split/train.jsonl`: Training set
- `split/val.jsonl`: Validation set  
- `split/test.jsonl`: Test set
- `23120334/{paper_id}/pred.json`: Predictions cho má»—i paper

**Thá»‘ng kÃª split**:

```
Split sizes (papers): {'test': 2, 'train': 528, 'val': 2}
partition
train    489406
test       2597
val        2574
```

---

### BÆ°á»›c 3: Training & Evaluation

Notebook: `notebooks/modeling.ipynb`

**Má»¥c Ä‘Ã­ch**:
- Train Random Forest model
- Hyperparameter tuning
- ÄÃ¡nh giÃ¡ báº±ng MRR@5

**Cáº¥u hÃ¬nh Optuna Hyperparameter Tuning**:

```python
# Optuna search space
N_TRIALS = 30
RANDOM_STATE = 42

params = {
    'n_estimators': trial.suggest_int('n_estimators', 100, 400, step=50),
    'max_depth': trial.suggest_int('max_depth', 5, 30, step=5),
    'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),
    'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 5),
    'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2']),
    'class_weight': trial.suggest_categorical('class_weight', ['balanced', 'balanced_subsample']),
    'random_state': RANDOM_STATE,
    'n_jobs': -1
}
```

**Cháº¡y (theo thá»© tá»± cell)**:

1. Cell cáº¥u hÃ¬nh + "Load Data"
2. Cell "Data Split Summary"
3. Cell "Feature Configuration"
4. Cell "Model Training" (Optuna)
5. Cell "Model Evaluation"
6. Cell "Feature Importance Analysis" (tÃ¹y chá»n)
7. Cell "Generate Predictions"

**Káº¿t quáº£**:

```
Best Parameters (Optuna):
{
    'n_estimators': 350,
    'max_depth': 15,
    'min_samples_split': 2,
    'min_samples_leaf': 5,
    'max_features': 'log2',
    'class_weight': 'balanced_subsample'
}

Best Val F1: 0.7072
Test MRR@5: 0.8911
Result: Excellent (>0.7)
```

**Model Ä‘Æ°á»£c lÆ°u táº¡i**: `models/citation_matcher_rf.pkl`

---

## Cáº¥u trÃºc dá»¯ liá»‡u

### bibitems.jsonl

Má»—i dÃ²ng lÃ  má»™t bibliography item:

```json
{
  "paper_id": "2408-02468",
  "key": "zhang2021counterfactual",
  "title": "Counterfactual Learning for Recommendation",
  "authors": ["Zhang", "Li", "Wang"],
  "year": 2021,
  "arxiv": "2112.12938",
  "venue": "arXiv"
}
```

### references.jsonl

Má»—i dÃ²ng lÃ  má»™t reference paper:

```json
{
  "paper_id": "2408-02468",
  "id": "2112.12938",
  "arxiv": "2112.12938",
  "title": "Counterfactual Learning for Recommendation",
  "authors": ["Zhang", "Li", "Wang"],
  "year": 2021
}
```

### matches_fe.jsonl

Má»—i dÃ²ng lÃ  má»™t cáº·p (bib_key, candidate) vá»›i features:

```json
{
  "paper_id": "2408-02468",
  "bib_key": "zhang2021counterfactual",
  "cand_id": "2112.12938",
  "score": 1.0,
  "levenshtein": 0.95,
  "jaccard": 0.88,
  "year_match": 1,
  "year_diff": 0,
  "source_year": 2021,
  "cand_year": 2021,
  "label": 1
}
```

### pred.json

File dá»± Ä‘oÃ¡n cho má»—i paper:

```json
{
  "partition": "test",
  "groundtruth": {
    "zhang2021counterfactual": "2112.12938",
    "li2022deep": "2201.12345"
  },
  "prediction": {
    "zhang2021counterfactual": ["2112.12938", "2112.12939", "2112.12940", "2112.12941", "2112.12942"],
    "li2022deep": ["2201.12345", "2201.12346", "2201.12347", "2201.12348", "2201.12349"]
  }
}
```

### manual_candidates.json

File chá»©a cÃ¡c mapping thá»§ cÃ´ng (manual labels) tá»« bib_key sang arxiv_id cho cÃ¡c papers. ÄÆ°á»£c sá»­ dá»¥ng Ä‘á»ƒ táº¡o ground truth labels trong quÃ¡ trÃ¬nh training:

```json
{
  "2408-02468": {
    "zhang2021counterfactual": "2112.12938",
    "li2022deep": "2201.12345"
  },
  "2408-02469": {
    "wang2023neural": "2301.12345",
    "chen2022transformer": "2205.67890"
  }
}
```

**Cáº¥u trÃºc**: Má»—i key lÃ  `paper_id`, giÃ¡ trá»‹ lÃ  má»™t dictionary mapping `bib_key` â†’ `arxiv_id` (candidate ID).

---

## Káº¿t quáº£

### Performance Metrics

| Metric | Value | Interpretation |
|--------|-------|----------------|
| **MRR@5** | 0.8911 | Excellent (>0.7) |
| **Test Queries** | 114 | Number of test citation keys |
| **Precision** | 0.98 | For class 1 (match) |
| **Recall** | 0.87 | For class 1 (match) |
| **F1-Score** | 0.92 | For class 1 (match) |

### Feature Importance

Theo thá»© tá»± quan trá»ng (vá»›i excluded features):

1. **author_lastname_match** - 0.587 (Feature quan trá»ng nháº¥t)
2. **year_diff** - 0.213 (ChÃªnh lá»‡ch nÄƒm)
3. **year_match** - 0.049 (Khá»›p nÄƒm)
4. **cand_year** - 0.046 (NÄƒm candidate)
5. **source_year** - 0.046 (NÄƒm source)
6. **author_overlap** - 0.039 (Overlap tÃ¡c giáº£)
7. **levenshtein** - 0.020 (Äá»™ tÆ°Æ¡ng Ä‘á»“ng chuá»—i)

### Model Configuration

```python
RandomForestClassifier(
    n_estimators=350,
    max_depth=15,
    min_samples_split=2,
    min_samples_leaf=5,
    max_features='log2',
    class_weight='balanced_subsample',
    random_state=42,
    n_jobs=-1
)
```

---

## Cáº¥u trÃºc thÆ° má»¥c

```
23120334/                          # ThÆ° má»¥c gá»‘c dá»± Ã¡n
â”œâ”€â”€ src/                           # Source code chÃ­nh
â”‚   â”œâ”€â”€ parse_util.py             # Parser LaTeX
â”‚   â”œâ”€â”€ match_utils.py            # Matching pipeline (tÃ­ch há»£p TF-IDF matching vÃ  text normalization)
â”‚   â”œâ”€â”€ feature_engineering_utils.py  # Feature computation
â”‚   â”œâ”€â”€ modeling_utils.py         # Training & evaluation
â”‚   â””â”€â”€ visualization.py          # Visualization helpers
â”‚
â”œâ”€â”€ notebooks/                     # Jupyter notebooks
â”‚   â”œâ”€â”€ parse_runner.ipynb        # BÆ°á»›c 1: Parse LaTeX
â”‚   â”œâ”€â”€ match_and_fe.ipynb        # BÆ°á»›c 2: Matching & FE
â”‚   â””â”€â”€ modeling.ipynb            # BÆ°á»›c 3: Training & Evaluation
â”‚
â”œâ”€â”€ aggregated/                    # Dá»¯ liá»‡u Ä‘Ã£ aggregate
â”‚   â”œâ”€â”€ bibitems.jsonl            # Bibliography items
â”‚   â”œâ”€â”€ references.jsonl          # References
â”‚   â”œâ”€â”€ matches_fe.jsonl          # Matched pairs vá»›i features
â”‚   â””â”€â”€ manual_candidates.json    # Manual labels (náº¿u cÃ³)
â”‚
â”œâ”€â”€ split/                         # Train/Val/Test splits
â”‚   â”œâ”€â”€ train.jsonl               # Training set
â”‚   â”œâ”€â”€ val.jsonl                 # Validation set
â”‚   â””â”€â”€ test.jsonl                # Test set
â”‚
â”œâ”€â”€ models/                        # Trained models
â”‚   â””â”€â”€ citation_matcher_rf.pkl   # Random Forest model
â”‚
â”œâ”€â”€ 23120334/                      # Papers data
â”‚   â”œâ”€â”€ 2408-02468/
â”‚   â”‚   â”œâ”€â”€ metadata.json
â”‚   â”‚   â”œâ”€â”€ references.json
â”‚   â”‚   â”œâ”€â”€ refs.bib               # Bibliography (generated)
â”‚   â”‚   â”œâ”€â”€ hierarchy.json         # Citation hierarchy (generated)
â”‚   â”‚   â”œâ”€â”€ pred.json             # Predictions
â”‚   â””â”€â”€ ...
â”œâ”€â”€ requirements.txt              # Dependencies
â””â”€â”€ README.md                     
```

### Module Dependencies

**`match_utils.py`** - Module trung tÃ¢m cho matching pipeline:
- **TÃ­ch há»£p Ä‘áº§y Ä‘á»§**: Chá»©a táº¥t cáº£ cÃ¡c hÃ m cáº§n thiáº¿t cho TF-IDF matching vÃ  text normalization
- **Text normalization**: Bao gá»“m `normalize_ref_text()`, `cleanup_formatting()`, `normalize_spaces()`, `protect_math()` (tÃ­ch há»£p tá»« `latex_parser_tree.py`)
- **TF-IDF matching**: Bao gá»“m `build_text()`, `compute_matches()` (tÃ­ch há»£p tá»« `reference_matcher_tfidf.py`)
- **KhÃ´ng cÃ³ external dependencies**: KhÃ´ng import tá»« `latex_parser_tree` hay `reference_matcher_tfidf` Ä‘á»ƒ trÃ¡nh circular imports

**`feature_engineering_utils.py`**:
- Cung cáº¥p cÃ¡c hÃ m tÃ­nh toÃ¡n features: `compute_features()`, `author_overlap()`, `author_lastname_match()`, `parse_year_int()`
- ÄÆ°á»£c sá»­ dá»¥ng bá»Ÿi `match_utils.py` vÃ  `modeling_utils.py`

**CÃ¡c modules khÃ¡c**:
- `parse_util.py`: Parser LaTeX Ä‘á»™c láº­p
- `modeling_utils.py`: Training vÃ  evaluation, sá»­ dá»¥ng `feature_engineering_utils.py`
- `visualization.py`: Visualization helpers Ä‘á»™c láº­p

---

## Troubleshooting

### Lá»—i: MemoryError khi training

**Giáº£i phÃ¡p**:
- Giáº£m `NUM` trong `match_and_fe.ipynb` (tá»« 600 xuá»‘ng 300)
- Giáº£m `n_jobs` trong GridSearchCV (tá»« 2 xuá»‘ng 1)
- Sá»­ dá»¥ng subsample nhá» hÆ¡n cho negative sampling

### Lá»—i: Missing split files

**Giáº£i phÃ¡p**:
- Äáº£m báº£o Ä‘Ã£ cháº¡y `match_and_fe.ipynb` Ä‘áº¿n cell cuá»‘i (split & pred.json)
- Kiá»ƒm tra `split/` directory cÃ³ Ä‘áº§y Ä‘á»§ 3 files

### Lá»—i: ImportError khi cháº¡y notebooks

**Giáº£i phÃ¡p**:
- Äáº£m báº£o Ä‘Ã£ cÃ i Ä‘áº·t dependencies: `pip install -r requirements.txt`
- Kiá»ƒm tra `sys.path` trong notebook cÃ³ trá» Ä‘Ãºng Ä‘áº¿n `src/`
- LÆ°u Ã½: `match_utils.py` Ä‘Ã£ tÃ­ch há»£p Ä‘áº§y Ä‘á»§ cÃ¡c functions cáº§n thiáº¿t, khÃ´ng cáº§n import tá»« `latex_parser_tree` hay `reference_matcher_tfidf`

---

## TÃ i liá»‡u tham kháº£o

- [scikit-learn Random Forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)
- [Mean Reciprocal Rank (MRR)](https://en.wikipedia.org/wiki/Mean_reciprocal_rank)
- [Entity Resolution Overview](https://en.wikipedia.org/wiki/Record_linkage)

---

## Acknowledgments

- Dataset tá»« arXiv
- Semantic Scholar API cho reference data
- scikit-learn team cho ML framework

---

**LiÃªn há»‡**: 23120334@student.hcmus.edu.vn 

---

